{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aspect-Based Sentiment Analysis: Findings from Natural Language\n",
    "#### Code File \\#5: Implementations for our Proposed Models (Task 3)\n",
    "\n",
    "Tahmeed Tureen - University of Michigan, Ann Arbor<br>\n",
    "Python file: <b>asba-proposed-model-Task3.ipynb</b> <br>\n",
    "Description: Code that implements the our proposed models/algorithms for 2014 Task 4 (Pontiki et al.; 2014)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load up relevant libraries\n",
    "import math\n",
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3156, 9)\n",
      "(557, 9)\n",
      "(1025, 5)\n"
     ]
    }
   ],
   "source": [
    "# Read in Data\n",
    "train_data = pickle.load(open(\"pickled_data/pickled_train_data.pkl\", \"rb\"))\n",
    "print(train_data.shape)\n",
    "test_data = pickle.load(open(\"pickled_data/pickled_test_data.pkl\", \"rb\"))\n",
    "print(test_data.shape)\n",
    "semEval_test_data = pickle.load(open(\"pickled_data/semEval_TestData.pkl\", \"rb\"))\n",
    "print(semEval_test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3713, 9)\n"
     ]
    }
   ],
   "source": [
    "full_data = pd.concat([train_data, test_data], ignore_index=True)\n",
    "print(full_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase A Task 3\n",
    "We will use three classifiers for Aspect-Categroy classifications:\n",
    "\n",
    "- Rule Based Algorithm (using word embeddings and aspect terms)\n",
    "- Multinomial Naive Bayes\n",
    "- Support Vector Machines\n",
    "\n",
    "We can take two approaches here, we can train a multi-class classifier... or we can train a multi-label classifier\n",
    "\n",
    "- multi-class: outcome is only 1-D \n",
    "- multi-label: outcome is > 1-D vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Load up relevant features from sklearn module\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Engineer the training and test sets\n",
    "\n",
    "We need to convert outcome so that it is multilabel..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3713, 5)\n",
      "(3713,)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1) # for reproducibility\n",
    "# Need to convert the Category-Labels into Arrays\n",
    "ml_Binarizer = MultiLabelBinarizer()\n",
    "full_Y = ml_Binarizer.fit_transform(full_data.Categories)\n",
    "\n",
    "\n",
    "full_X = full_data.Review\n",
    "\n",
    "print(full_Y.shape) # Y's\n",
    "print(full_X.shape) # reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3156,)\n",
      "(557,)\n",
      "(3156, 5)\n",
      "(557, 5)\n"
     ]
    }
   ],
   "source": [
    "# Need to do train - test split\n",
    "train_X, test_X, train_Y, test_Y = train_test_split(full_X, full_Y, test_size = 0.15) \n",
    "\n",
    "print(train_X.shape)\n",
    "print(test_X.shape)\n",
    "print(train_Y.shape)\n",
    "print(test_Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6302\n",
      "0.8225\n"
     ]
    }
   ],
   "source": [
    "pipeline_NB = Pipeline([('vect', CountVectorizer(stop_words = \"english\", ngram_range=(1,1))),\n",
    "                        ('clf', OneVsRestClassifier(MultinomialNB(alpha = 0.1))),])\n",
    "NB_classifier = pipeline_NB.fit(X = train_X, y = train_Y)\n",
    "predict_Y = NB_classifier.predict(test_X)\n",
    "print(round(accuracy_score(y_true=test_Y, y_pred=predict_Y),4))\n",
    "print(round(f1_score(test_Y, predict_Y, average = 'weighted'), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6661\n",
      "0.8256\n"
     ]
    }
   ],
   "source": [
    "pipeline_NB = Pipeline([('vect', CountVectorizer(stop_words = \"english\", ngram_range=(1,2))),\n",
    "                        ('clf', OneVsRestClassifier(MultinomialNB(alpha = 0.1))),])\n",
    "NB_classifier = pipeline_NB.fit(X = train_X, y = train_Y)\n",
    "predict_Y = NB_classifier.predict(test_X)\n",
    "print(round(accuracy_score(y_true=test_Y, y_pred=predict_Y),4))\n",
    "print(round(f1_score(test_Y, predict_Y, average = 'weighted'), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6715\n",
      "0.8276\n"
     ]
    }
   ],
   "source": [
    "pipeline_NB = Pipeline([('vect', CountVectorizer(stop_words = \"english\", ngram_range=(1,3))),\n",
    "                        ('clf', OneVsRestClassifier(MultinomialNB(alpha = 0.1))),])\n",
    "NB_classifier = pipeline_NB.fit(X = train_X, y = train_Y)\n",
    "predict_Y = NB_classifier.predict(test_X)\n",
    "print(round(accuracy_score(y_true=test_Y, y_pred=predict_Y),4))\n",
    "print(round(f1_score(test_Y, predict_Y, average = 'weighted'), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We beat the baseline metric! Let's look at some of the other statistical learning models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7828\n",
      "0.8851\n"
     ]
    }
   ],
   "source": [
    "pipeline_SVM = Pipeline([('vect', CountVectorizer(stop_words= \"english\", ngram_range=(1,1))),\n",
    "                        ('clf', OneVsRestClassifier(LinearSVC(penalty='l2')))])\n",
    "SVM_classifier = pipeline_SVM.fit(X = train_X, y = train_Y)\n",
    "predict_Y = SVM_classifier.predict(test_X)\n",
    "print(round(accuracy_score(y_true=test_Y, y_pred=predict_Y),4))\n",
    "print(round(f1_score(test_Y, predict_Y, average = 'weighted'), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7935\n",
      "0.8834\n"
     ]
    }
   ],
   "source": [
    "pipeline_SVM = Pipeline([('vect', CountVectorizer(stop_words= \"english\", ngram_range=(1,2))),\n",
    "                        ('clf', OneVsRestClassifier(LinearSVC(penalty='l2')))])\n",
    "SVM_classifier = pipeline_SVM.fit(X = train_X, y = train_Y)\n",
    "predict_Y = SVM_classifier.predict(test_X)\n",
    "print(round(accuracy_score(y_true=test_Y, y_pred=predict_Y),4))\n",
    "print(round(f1_score(test_Y, predict_Y, average = 'weighted'), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7882\n",
      "0.8787\n"
     ]
    }
   ],
   "source": [
    "pipeline_SVM = Pipeline([('vect', CountVectorizer(stop_words= \"english\", ngram_range=(1,3))),\n",
    "                        ('clf', OneVsRestClassifier(LinearSVC(penalty='l2')))])\n",
    "SVM_classifier = pipeline_SVM.fit(X = train_X, y = train_Y)\n",
    "predict_Y = SVM_classifier.predict(test_X)\n",
    "\n",
    "print(round(accuracy_score(y_true=test_Y, y_pred=predict_Y),4))\n",
    "print(round(f1_score(test_Y, predict_Y, average = 'weighted'), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7271\n",
      "0.8636\n"
     ]
    }
   ],
   "source": [
    "pipeline_LogitRegression = Pipeline([('vect', CountVectorizer(stop_words= \"english\")),\n",
    "                        ('clf', OneVsRestClassifier(LogisticRegression()))])\n",
    "LR_classifier = pipeline_LogitRegression.fit(X = train_X, y = train_Y)\n",
    "predict_Y = LR_classifier.predict(test_X)\n",
    "\n",
    "print(round(accuracy_score(y_true=test_Y, y_pred=predict_Y),4))\n",
    "print(round(f1_score(test_Y, predict_Y, average = 'weighted'), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.754\n",
      "0.8755\n"
     ]
    }
   ],
   "source": [
    "pipeline_LogitRegression = Pipeline([('vect', CountVectorizer(stop_words= \"english\", ngram_range=(1,2))),\n",
    "                        ('clf', OneVsRestClassifier(LogisticRegression()))])\n",
    "LR_classifier = pipeline_LogitRegression.fit(X = train_X, y = train_Y)\n",
    "predict_Y = LR_classifier.predict(test_X)\n",
    "\n",
    "print(round(accuracy_score(y_true=test_Y, y_pred=predict_Y),4))\n",
    "print(round(f1_score(test_Y, predict_Y, average = 'weighted'), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.754\n",
      "0.8729\n"
     ]
    }
   ],
   "source": [
    "pipeline_LogitRegression = Pipeline([('vect', CountVectorizer(stop_words= \"english\", ngram_range=(1,3))),\n",
    "                        ('clf', OneVsRestClassifier(LogisticRegression()))])\n",
    "LR_classifier = pipeline_LogitRegression.fit(X = train_X, y = train_Y)\n",
    "predict_Y = LR_classifier.predict(test_X)\n",
    "\n",
    "print(round(accuracy_score(y_true=test_Y, y_pred=predict_Y),4))\n",
    "print(round(f1_score(test_Y, predict_Y, average = 'weighted'), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rule-Based Approach\n",
    "\n",
    "- Assume that we have successfully extracted the aspect terms\n",
    "- Check word similarities for the aspect terms with the aspect categories\n",
    "- The category with the highest similarity, gets assigned as the Category for that label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
