{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aspect-Based Sentiment Analysis: Findings from Natural Language\n",
    "#### Code File \\#4: Implementations for our Proposed Models (Task 3)\n",
    "\n",
    "Tahmeed Tureen - University of Michigan, Ann Arbor<br>\n",
    "Python file: <b>asba-proposed-model-Task3.ipynb</b> <br>\n",
    "Description: Code that implements the our proposed models/algorithms for 2014 Task 4 (Pontiki et al.; 2014)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load up relevant libraries\n",
    "import math\n",
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3156, 9)\n",
      "(557, 9)\n",
      "(1025, 5)\n"
     ]
    }
   ],
   "source": [
    "# Read in Data\n",
    "train_data = pickle.load(open(\"pickled_data/pickled_train_data.pkl\", \"rb\"))\n",
    "print(train_data.shape)\n",
    "test_data = pickle.load(open(\"pickled_data/pickled_test_data.pkl\", \"rb\"))\n",
    "print(test_data.shape)\n",
    "semEval_test_data = pickle.load(open(\"pickled_data/semEval_TestData.pkl\", \"rb\"))\n",
    "print(semEval_test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3713, 9)\n"
     ]
    }
   ],
   "source": [
    "# pd.concat([a,b],ignore_index=True)\n",
    "\n",
    "full_data = pd.concat([train_data, test_data], ignore_index=True)\n",
    "print(full_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase A Task 3\n",
    "We will use three classifiers for Aspect-Categroy classifications:\n",
    "\n",
    "- Rule Based Algorithm (using word embeddings and aspect terms)\n",
    "- Multinomial Naive Bayes\n",
    "- Support Vector Machines\n",
    "\n",
    "We can take two approaches here, we can train a multi-class classifier... or we can train a multi-label classifier\n",
    "\n",
    "- multi-class: outcome is only 1-D \n",
    "- multi-label: outcome is > 1-D vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Load up relevant features from sklearn module\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Engineer the training and test sets\n",
    "\n",
    "We need to convert outcome so that it is multilabel..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3713, 5)\n",
      "(3713,)\n"
     ]
    }
   ],
   "source": [
    "# Need to convert the Category-Labels into Arrays\n",
    "ml_Binarizer = MultiLabelBinarizer()\n",
    "full_Y = ml_Binarizer.fit_transform(full_data.Categories)\n",
    "full_X = full_data.Review\n",
    "\n",
    "print(full_Y.shape) # Y's\n",
    "print(full_X.shape) # reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3156,)\n",
      "(557,)\n",
      "(3156, 5)\n",
      "(557, 5)\n"
     ]
    }
   ],
   "source": [
    "# Need to do train - test split\n",
    "train_X, test_X, train_Y, test_Y = train_test_split(full_X, full_Y, test_size = 0.15) \n",
    "\n",
    "print(train_X.shape)\n",
    "print(test_X.shape)\n",
    "print(train_Y.shape)\n",
    "print(test_Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6588868940754039"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_NB = Pipeline([('vect', CountVectorizer(stop_words = \"english\", ngram_range=(1,1))),\n",
    "                        ('clf', OneVsRestClassifier(MultinomialNB(alpha = 0.1))),])\n",
    "NB_classifier = pipeline_NB.fit(X = train_X, y = train_Y)\n",
    "predict_Y = NB_classifier.predict(test_X)\n",
    "accuracy_score(y_true=test_Y, y_pred=predict_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7073608617594255"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_NB = Pipeline([('vect', CountVectorizer(stop_words = \"english\", ngram_range=(1,2))),\n",
    "                        ('clf', OneVsRestClassifier(MultinomialNB(alpha = 0.1))),])\n",
    "NB_classifier = pipeline_NB.fit(X = train_X, y = train_Y)\n",
    "predict_Y = NB_classifier.predict(test_X)\n",
    "accuracy_score(y_true=test_Y, y_pred=predict_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7217235188509874"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_NB = Pipeline([('vect', CountVectorizer(stop_words = \"english\", ngram_range=(1,3))),\n",
    "                        ('clf', OneVsRestClassifier(MultinomialNB(alpha = 0.1))),])\n",
    "NB_classifier = pipeline_NB.fit(X = train_X, y = train_Y)\n",
    "predict_Y = NB_classifier.predict(test_X)\n",
    "accuracy_score(y_true=test_Y, y_pred=predict_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We beat the baseline metric! Let's look at some of the other statistical learning models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7630161579892281"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_SVM = Pipeline([('vect', CountVectorizer(stop_words= \"english\", ngram_range=(1,1))),\n",
    "                        ('clf', OneVsRestClassifier(LinearSVC(penalty='l2')))])\n",
    "SVM_classifier = pipeline_SVM.fit(X = train_X, y = train_Y)\n",
    "predict_Y = SVM_classifier.predict(test_X)\n",
    "accuracy_score(y_true=test_Y, y_pred=predict_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7791741472172352"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_SVM = Pipeline([('vect', CountVectorizer(stop_words= \"english\", ngram_range=(1,2))),\n",
    "                        ('clf', OneVsRestClassifier(LinearSVC(penalty='l2')))])\n",
    "SVM_classifier = pipeline_SVM.fit(X = train_X, y = train_Y)\n",
    "predict_Y = SVM_classifier.predict(test_X)\n",
    "accuracy_score(y_true=test_Y, y_pred=predict_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7719928186714542"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_SVM = Pipeline([('vect', CountVectorizer(stop_words= \"english\", ngram_range=(1,3))),\n",
    "                        ('clf', OneVsRestClassifier(LinearSVC(penalty='l2')))])\n",
    "SVM_classifier = pipeline_SVM.fit(X = train_X, y = train_Y)\n",
    "predict_Y = SVM_classifier.predict(test_X)\n",
    "accuracy_score(y_true=test_Y, y_pred=predict_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7127468581687613"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_LogitRegression = Pipeline([('vect', CountVectorizer(stop_words= \"english\")),\n",
    "                        ('clf', OneVsRestClassifier(LogisticRegression()))])\n",
    "LR_classifier = pipeline_LogitRegression.fit(X = train_X, y = train_Y)\n",
    "predict_Y = LR_classifier.predict(test_X)\n",
    "accuracy_score(y_true=test_Y, y_pred=predict_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7504488330341114"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_LogitRegression = Pipeline([('vect', CountVectorizer(stop_words= \"english\", ngram_range=(1,2))),\n",
    "                        ('clf', OneVsRestClassifier(LogisticRegression()))])\n",
    "LR_classifier = pipeline_LogitRegression.fit(X = train_X, y = train_Y)\n",
    "predict_Y = LR_classifier.predict(test_X)\n",
    "accuracy_score(y_true=test_Y, y_pred=predict_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.748653500897666"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_LogitRegression = Pipeline([('vect', CountVectorizer(stop_words= \"english\", ngram_range=(1,3))),\n",
    "                        ('clf', OneVsRestClassifier(LogisticRegression()))])\n",
    "LR_classifier = pipeline_LogitRegression.fit(X = train_X, y = train_Y)\n",
    "predict_Y = LR_classifier.predict(test_X)\n",
    "accuracy_score(y_true=test_Y, y_pred=predict_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rule-Based Approach\n",
    "\n",
    "- Assume that we have successfully extracted the aspect terms\n",
    "- Check word similarities for the aspect terms with the aspect categories\n",
    "- The category with the highest similarity, gets assigned as the Category for that label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
