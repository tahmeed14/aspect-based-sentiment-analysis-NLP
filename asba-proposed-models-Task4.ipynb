{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aspect-Based Sentiment Analysis: Findings from Natural Language\n",
    "#### Code File \\#4: Implementations for our Proposed Models (Task 4)\n",
    "\n",
    "Tahmeed Tureen - University of Michigan, Ann Arbor<br>\n",
    "Python file: <b>asba-proposed-models-Task2.ipynb</b> <br>\n",
    "Description: Code that implements the our proposed models/algorithms for 2014 Task 4 (Pontiki et al.; 2014)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3156, 9)\n",
      "(557, 9)\n",
      "(1025, 5)\n"
     ]
    }
   ],
   "source": [
    "# Read in Data\n",
    "train_data = pickle.load(open(\"pickled_data/pickled_train_data.pkl\", \"rb\"))\n",
    "print(train_data.shape)\n",
    "test_data = pickle.load(open(\"pickled_data/pickled_test_data.pkl\", \"rb\"))\n",
    "print(test_data.shape)\n",
    "semEval_test_data = pickle.load(open(\"pickled_data/semEval_TestData.pkl\", \"rb\"))\n",
    "print(semEval_test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3713, 9)\n"
     ]
    }
   ],
   "source": [
    "full_data = pd.concat([train_data, test_data], ignore_index=True)\n",
    "print(full_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase A Task 4\n",
    "We will use three classifiers for Category-Polarity classifications:\n",
    "\n",
    "**Supervised**:\n",
    "- Multinomial Naive Bayes\n",
    "- Support Vector Machines\n",
    "- Logistic Regression\n",
    "- (all of them are performed using unigram, bigrams, and trigrams)\n",
    "\n",
    "**Unsupervised**:\n",
    "- Rule Based Algorithm (using word embeddings, POS tagging, Dependency Parsing, and Opinion Lexicons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Load up relevant features from sklearn module\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3713, 3)\n",
      "(3713,)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1) # for reproducibility\n",
    "# Need to convert the Category-Labels into Arrays\n",
    "ml_Binarizer = MultiLabelBinarizer()\n",
    "full_Y = ml_Binarizer.fit_transform(full_data.Category_Polarities)\n",
    "full_X = full_data.Review\n",
    "\n",
    "print(full_Y.shape) # Y's\n",
    "print(full_X.shape) # reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3156,)\n",
      "(557,)\n",
      "(3156, 3)\n",
      "(557, 3)\n"
     ]
    }
   ],
   "source": [
    "# Need to do train - test split\n",
    "train_X, test_X, train_Y, test_Y = train_test_split(full_X, full_Y, test_size = 0.15) \n",
    "\n",
    "print(train_X.shape)\n",
    "print(test_X.shape)\n",
    "print(train_Y.shape)\n",
    "print(test_Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6499"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_NB = Pipeline([('vect', CountVectorizer(stop_words = \"english\", ngram_range=(1,1))),\n",
    "                        ('clf', OneVsRestClassifier(MultinomialNB(alpha = 0.1))),])\n",
    "NB_classifier = pipeline_NB.fit(X = train_X, y = train_Y)\n",
    "predict_Y = NB_classifier.predict(test_X)\n",
    "round(accuracy_score(y_true=test_Y, y_pred=predict_Y),4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6786"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_NB = Pipeline([('vect', CountVectorizer(stop_words = \"english\", ngram_range=(1,2))),\n",
    "                        ('clf', OneVsRestClassifier(MultinomialNB(alpha = 0.1))),])\n",
    "NB_classifier = pipeline_NB.fit(X = train_X, y = train_Y)\n",
    "predict_Y = NB_classifier.predict(test_X)\n",
    "round(accuracy_score(y_true=test_Y, y_pred=predict_Y),4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6715"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_NB = Pipeline([('vect', CountVectorizer(stop_words = \"english\", ngram_range=(1,3))),\n",
    "                        ('clf', OneVsRestClassifier(MultinomialNB(alpha = 0.1))),])\n",
    "NB_classifier = pipeline_NB.fit(X = train_X, y = train_Y)\n",
    "predict_Y = NB_classifier.predict(test_X)\n",
    "\n",
    "round(accuracy_score(y_true=test_Y, y_pred=predict_Y),4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6517"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_SVM = Pipeline([('vect', CountVectorizer(stop_words= \"english\", ngram_range=(1,1))),\n",
    "                        ('clf', OneVsRestClassifier(LinearSVC(penalty='l2')))])\n",
    "SVM_classifier = pipeline_SVM.fit(X = train_X, y = train_Y)\n",
    "predict_Y = SVM_classifier.predict(test_X)\n",
    "\n",
    "round(accuracy_score(y_true=test_Y, y_pred=predict_Y),4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6697"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_SVM = Pipeline([('vect', CountVectorizer(stop_words= \"english\", ngram_range=(1,2))),\n",
    "                        ('clf', OneVsRestClassifier(LinearSVC(penalty='l2')))])\n",
    "SVM_classifier = pipeline_SVM.fit(X = train_X, y = train_Y)\n",
    "predict_Y = SVM_classifier.predict(test_X)\n",
    "\n",
    "round(accuracy_score(y_true=test_Y, y_pred=predict_Y),4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6679"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_SVM = Pipeline([('vect', CountVectorizer(stop_words= \"english\", ngram_range=(1,3))),\n",
    "                        ('clf', OneVsRestClassifier(LinearSVC(penalty='l2')))])\n",
    "SVM_classifier = pipeline_SVM.fit(X = train_X, y = train_Y)\n",
    "predict_Y = SVM_classifier.predict(test_X)\n",
    "round(accuracy_score(y_true=test_Y, y_pred=predict_Y),4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6427"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_LogitRegression = Pipeline([('vect', CountVectorizer(stop_words= \"english\")),\n",
    "                        ('clf', OneVsRestClassifier(LogisticRegression()))])\n",
    "LR_classifier = pipeline_LogitRegression.fit(X = train_X, y = train_Y)\n",
    "predict_Y = LR_classifier.predict(test_X)\n",
    "\n",
    "round(accuracy_score(y_true=test_Y, y_pred=predict_Y),4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6697"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_LogitRegression = Pipeline([('vect', CountVectorizer(stop_words= \"english\", ngram_range=(1,2))),\n",
    "                        ('clf', OneVsRestClassifier(LogisticRegression()))])\n",
    "LR_classifier = pipeline_LogitRegression.fit(X = train_X, y = train_Y)\n",
    "predict_Y = LR_classifier.predict(test_X)\n",
    "\n",
    "round(accuracy_score(y_true=test_Y, y_pred=predict_Y),4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6607"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_LogitRegression = Pipeline([('vect', CountVectorizer(stop_words= \"english\", ngram_range=(1,3))),\n",
    "                        ('clf', OneVsRestClassifier(LogisticRegression()))])\n",
    "LR_classifier = pipeline_LogitRegression.fit(X = train_X, y = train_Y)\n",
    "predict_Y = LR_classifier.predict(test_X)\n",
    "\n",
    "round(accuracy_score(y_true=test_Y, y_pred=predict_Y),4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rule-Based Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
